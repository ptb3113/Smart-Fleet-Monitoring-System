{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c7ebdc",
   "metadata": {},
   "source": [
    "# 01. Data Processing and System Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46466b7",
   "metadata": {},
   "source": [
    "Step 1: Set Up the Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d0b233c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: dask in /opt/anaconda3/lib/python3.11/site-packages (2023.11.0)\n",
      "Requirement already satisfied: sqlalchemy in /opt/anaconda3/lib/python3.11/site-packages (2.0.25)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click>=8.1 in /opt/anaconda3/lib/python3.11/site-packages (from dask) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from dask) (2.2.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /opt/anaconda3/lib/python3.11/site-packages (from dask) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from dask) (23.2)\n",
      "Requirement already satisfied: partd>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from dask) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/anaconda3/lib/python3.11/site-packages (from dask) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from dask) (0.12.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.13.0 in /opt/anaconda3/lib/python3.11/site-packages (from dask) (7.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from sqlalchemy) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from sqlalchemy) (3.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from importlib-metadata>=4.13.0->dask) (3.17.0)\n",
      "Requirement already satisfied: locket in /opt/anaconda3/lib/python3.11/site-packages (from partd>=1.2.0->dask) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Step 1.1: Install Required Libraries\n",
    "!pip install pandas dask sqlalchemy numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14c512f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ptb/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Step 1.2: Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73136a",
   "metadata": {},
   "source": [
    "Step 2: Load and Process the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.1: Load Dataset into Pandas DataFrame\n",
    "df = pd.read_csv('fleet_health_performance_dataset.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce444b25",
   "metadata": {},
   "source": [
    "2.2 Basic Data Preprocessing with Pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec06dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.2.1: Handle Missing Values\n",
    "df.fillna(method='ffill', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.2.2: Convert Timestamp to Datetime\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.2.3: Convert Categorical Columns to Category Type\n",
    "df['Vehicle ID'] = df['Vehicle ID'].astype('category')\n",
    "\n",
    "# Display the DataFrame after preprocessing\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047f180",
   "metadata": {},
   "source": [
    "2.3 Upload Data to SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2857008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.3.1: Establish a Connection to the SQLite Database\n",
    "import sqlite3\n",
    "\n",
    "# Create a connection to the SQLite database\n",
    "conn = sqlite3.connect('fleet_health_performance.db')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.3.2: Write DataFrame to SQLite Database\n",
    "# Write the DataFrame to the SQLite database\n",
    "df.to_sql('fleet_data', conn, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c32cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2.3.3: Verify Data Load\n",
    "# Query the database to verify the data load\n",
    "result = pd.read_sql('SELECT * FROM fleet_data LIMIT 5;', conn)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf09dc7",
   "metadata": {},
   "source": [
    "Step 3: Data Processing with Dask and SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7dd6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.1: Load Data from CSV into Dask DataFrame\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Load the data from the CSV file using Dask\n",
    "dask_df = dd.read_csv('fleet_health_performance_dataset.csv')\n",
    "\n",
    "# Show the first few rows to verify the load\n",
    "dask_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30487c53",
   "metadata": {},
   "source": [
    "3.2 Data Transformation with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d02f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.2.1: Calculate Average Engine Temperature per Vehicle with Dask\n",
    "avg_engine_temp = dask_df.groupby('Vehicle ID')['Engine Temp (째C)'].mean().compute()\n",
    "\n",
    "# Display the result\n",
    "print(avg_engine_temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b1c91",
   "metadata": {},
   "source": [
    "3.3 Data Processing with SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c24172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3.3.1: Query SQL Database for Average Engine Temperature\n",
    "# Import SQLite3 for database operations\n",
    "import sqlite3\n",
    "\n",
    "# Establish a connection to the SQLite database\n",
    "conn = sqlite3.connect('fleet_health_performance.db')\n",
    "\n",
    "# Perform the query\n",
    "query = \"\"\"\n",
    "SELECT \"Vehicle ID\", AVG(\"Engine Temp (째C)\") as avg_engine_temp\n",
    "FROM fleet_data\n",
    "GROUP BY \"Vehicle ID\"\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and load the result into a Pandas DataFrame\n",
    "avg_engine_temp_sql = pd.read_sql(query, con=conn)\n",
    "\n",
    "# Display the result\n",
    "print(avg_engine_temp_sql)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bffb07",
   "metadata": {},
   "source": [
    "Step 4: Automate Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.1: Import Required Libraries\n",
    "import time\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c9bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.2: Define the Data Processing Function\n",
    "def preprocess_and_query_data():\n",
    "    print(\"Starting data preprocessing and SQL queries...\")\n",
    "\n",
    "    # Load the data into Dask (or Pandas for smaller datasets)\n",
    "    dask_df = dd.read_csv('fleet_health_performance_dataset.csv')\n",
    "\n",
    "    # Perform a transformation (e.g., calculate average engine temperature)\n",
    "    avg_engine_temp = dask_df.groupby('Vehicle ID')['Engine Temp (째C)'].mean().compute()\n",
    "    print(\"Average Engine Temperature Calculation Done.\")\n",
    "\n",
    "    # Example SQL operation\n",
    "    conn = sqlite3.connect('fleet_health_performance.db')\n",
    "    query = \"\"\"\n",
    "    SELECT \"Vehicle ID\", AVG(\"Engine Temp (째C)\") as avg_engine_temp\n",
    "    FROM fleet_data\n",
    "    GROUP BY \"Vehicle ID\"\n",
    "    \"\"\"\n",
    "    avg_engine_temp_sql = pd.read_sql(query, con=conn)\n",
    "    print(\"SQL Query Done.\")\n",
    "    print(avg_engine_temp_sql)\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Data processing and SQL queries completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0df0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4.3: Run the Task in a Loop\n",
    "while True:\n",
    "    preprocess_and_query_data()\n",
    "    print(\"Task completed. Waiting for the next run...\")\n",
    "    time.sleep(86400)  # Sleep for 24 hours (86400 seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95258352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017d5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
